<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming">
  <meta name="keywords" content="Model-Based Reinforcement Learning, Image-Based Reinforcement Learning, Goal-Conditioned Reinforcement Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
   
  <!-- <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://hany606.github.io">Hany Hamed*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ksb21st.github.io/">Subin Kim*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://x.com/dongyeongkim3">Dongyeong Kim</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.jaesikyoon.com/">Jaesik Yoon</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href="https://mlml.kaist.ac.kr/sungjinahn">Sungjin Ahn</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>KAIST,</span>
            <span class="author-block"><sup>2</sup>SAP</span>
            <span class="author-block"><sup>*</sup>Equal Contribution (random order)</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2402.18866"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2402.18866"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ahn-ml/drstrategy"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/figures/gif/9rooms_goal.gif" alt="" width="300" height="auto">
      <img src="static/figures/gif/3dmaze_goal.gif" alt="" width="300" height="auto">
      <img src="static/figures/gif/robokitchen_goal.gif" alt="" width="300" height="auto">

      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2> -->
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <!-- <div class="item item-steve">
          <img src="static/figures/gif/9rooms_goal.gif" alt="">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!-- <div class="item item-steve">
          <img src="static/figures/gif/9rooms_goal.gif" alt="">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div> -->
      </div>
    </div>
  </div>
</section> 



<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <img src="static/figures/gif/9rooms_goal.gif" alt="">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
                <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Model-based reinforcement learning (MBRL) has been a primary approach to ameliorating the sample efficiency issue as well as to make a generalist
            agent. However, there has not been much effort toward enhancing the strategy of dreaming itself. Therefore, it is a question whether and how an agent can “dream better” in a more structured and strategic way. In this paper, inspired by the observation from cognitive science suggesting that humans use a spatial divide-and-conquer strategy in
            planning, we propose a new MBRL agent, called Dr. Strategy, which is equipped with a novel
            Dreaming Strategy. The proposed agent realizes a version of divide-and-conquer-like strategy in
            dreaming. This is achieved by learning a set of latent landmarks and then utilizing these to learn
            a landmark-conditioned highway policy. With the highway policy, the agent can first learn in the
            dream to move to a landmark, and from there it tackles the exploration and achievement task in a
            more focused way. In experiments, we show that the proposed model outperforms prior pixel-based
            MBRL methods in various visually complex and partially observable navigation tasks.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="column">
      <div class="content">
        <h2 class="title is-3">Motivation</h2>
        <p>
          A crucial capability of generalist agents, such as humans, is to explore environments and acquire the abilities needed to achieve various goals, continuously and in an open-ended way. We raise the question of whether and how a model-based generalist RL agent can “dream better” in a more structured and strategic way.
        </p>
      </div>
    </div>

    <div class="column">
      <figure>
        <img src="static/figures/architecture/fig1.png" alt="" width="600" height="auto">
        <figcaption>Figure 1. (Left) In the real world, humans maintain a hierarchical
          spatial structure for easy navigation. (Right) Trying to memorize
          all the streets on the map can lead to an overwhelming amount
          of information, making it difficult to retain the information effectively. (Middle) In contrast, choosing to travel by train to move
          between cities and transfer to a taxi at the terminal minimizes the
          complexity, allowing one to concentrate on local routes starting
          from the terminal near the destination.</figcaption>
     </figure>
    </div>
    <div class="column">
      <div class="content">
        <p>
          <br>
          We propose a strategic model-based generalist agent, <b>Dr. Strategy (short for “Dream Strategy”)</b>.
          Our key idea is that a divide-and-conquer approach leveraging the structure of latent landmarks can enhance the efﬁciency of dreaming in MBRL and promote better exploration and achievement quality of a generalist agent.
        </p>
      </div>
    </div>



    <!-- <div class="column">
      <div class="content">
        <h2 class="title is-3">Dr. Strategy</h2>
        <p>
          BlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBla
        </p>
      </div>
    </div> -->

    <div class="column">
      <figure>
        <img src="static/figures/architecture/fig2.png" alt="">
        <img src="static/figures/architecture/fig3.png" alt="">
        <figcaption>      Figure 2. Comparison between Dr. Strategy and LEXA. a. We construct latent landmarks and train Highway policy πl(at|st, l),
          Explorer πe(at|st), and Achiever πg (at|st, eg ) in imagination. The Achiever is trained by Focused Sampling, which is conditioning
          goals within a small number of steps instead of random sampling. All three policies are purely trained with imagined trajectories from
          the world model. b. During exploration, we only evaluate the landmarks, and call the landmark with the highest exploration potential
          “Curious Landmark" (C-Landmark). In a real environment, the Highway policy moves to the curious landmark, and the Explorer resumes
          exploration. The agent iterates training and exploration with a certain frequency TF . c. During test time, we find the landmark that is
          nearest to the given pixel-level goal (G-Landmark). The Highway policy reaches G-Landmark, and the Achiever proceeds to achieve the
          goal immediately after. The blue boxes in the bottom half of the figure indicate the modules of LEXA, which are Explorer and Achiever
          without focused sampling and landmarks.
        </figcaption>

        </figure>    

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div> -->
    </div>
    <!--/ Matting. -->

    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2>

        <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>
        <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div> -->
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

    <div class="column">
      <div class="content">
        <h2 class="title is-3">Environments</h2>
        <!-- <p>
          BlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBla
        </p> -->
      </div>
    </div>


    
    <div class="column">
      <figure>
        <img src="static/figures/appendix/envs_overview.png" alt="" width="600" height="auto">
        <figcaption> Figure 3. Illustration of all the used environments. (a-c) Partially Observable 2D Navigation, (d-e) First-person view 3D maze navigation
          and (f) RoboKitchen. (b) shows the spiral 9-rooms in which the closed gates are highlighted in white, (d-e) showing the 3D-Maze
          environments without the floor color for easy visualizations of the walls.
        </figcaption>

        </figure>   
    </div>

    <div class="column">
      <figure>
        <img src="static/figures/appendix/envs_goals.png" alt="" width="1000" height="auto">
        <figcaption> Figure 4. Zero-shot evaluation goals on each environment. Our agent is evaluated given unseen goals in the evaluation phase. (a) and
          (b) illustrate the goals in navigation environments and (c) shows the goal images of the RoboKitchen benchmark.
      
        </figcaption>

        </figure>    

      
    </div>

    
    <div class="column">
      <div class="content">
        <h2 class="title is-3">Main results</h2>
        <!-- <p>
          BlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBla
        </p> -->
      </div>
    </div>

    <div class="column">
      <figure>
      <img src="static/figures/results/main/results_combined.png" alt="">
      <img src="static/figures/results/main/table.png" alt="">

      <figcaption>     Figure 5. Zero-shot evaluation of the baselines across different environments. Each baseline is evaluated given a goal image from the
        environment’s test set. Dr. Strategy significantly outperforms other baselines in most of the navigation tasks, while achieving comparable
        results in RoboKitchen. The success rate is reported with the mean and standard deviation across 3 different random seeds.
            
      </figcaption>

      </figure>    
    </div>
    <div class="columns is-centered">
    </div>
  
  



    <div class="column">
      <figure>
        <img src="static/figures/results/qualitative/qualitative_traj_seq.png" alt="">
        <figcaption>         Figure 6. Qualitative results of Dr. Strategy’s zero-shot evaluation trajectories. Given the goal, the proposed agent finds the nearest
          landmark. We visualize it by inferring the latent state using the world model, and then it is reconstructed. The agent starts in the initial
          state and then uses the highway policy conditioned on the closest landmark. Upon meeting the termination criteria, it then switches to the
          focused achiever policy, conditioned on the given goal.          
        </figcaption>
  
        </figure>    
  
    </div>


    <div class="column">
      <div class="content">
        <h2 class="title is-3">Ablation Studies</h2>
        <!-- <p>
          BlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBlaBla
        </p> -->
      </div>
    </div>


    <div class="column">
      <figure>
        <img src="static/figures/results/ablation/results_ablation_modules_v3.png" alt="">
        <figcaption>
          Figure 7. Ablation results for SE, SA, FS. showing the influence
          of using Strategy to Explore (SE), Strategy to Achieve (SA), and
          focused sampling (FS) to Dr. Strategy’s zero-shot success rate         
        </figcaption>
        </figure>    
  
    </div>


  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
      hamed2024dr,
      title={Dr. Strategy: Model-Based Generalist Agents with Strategic Dreaming},
      author={Hany Hamed and Subin Kim and Dongyeong Kim and Jaesik Yoon and Sungjin Ahn},
      booktitle={Forty-first International Conference on Machine Learning},
      year={2024},
      url={https://openreview.net/forum?id=HsseRq2FAx}
      }
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/dr_strategy_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/ahn-ml/drstrategy" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The website template was borrowed from <a href="https://github.com/nerfies/nerfies.github.io"> Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
